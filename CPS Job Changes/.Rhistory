# Most common transition: OCC Measure
head(subset(j1, same_cps != 1) %>% arrange(desc(pct_tot)), 10)[c("ONET18_Title_LY","ONET18_Title", "pct_tot")]
# Most common transition: ONET Measure
head(subset(j1, ONET18_SOC == ONET18_SOC_LY) %>% arrange(desc(pct_tot)), 10)[c("ONET18_Title_LY","ONET18_Title")]
# Most stable jobs: OCC measure
head(subset(j1, same_cps == 1) %>% arrange(pct_socly), 10)[c("ONET18_Title_LY","ONET18_Title", "pct_socly")]
# Most stable jobs: ONET measure
head(subset(j1, ONET18_SOC == ONET18_SOC_LY) %>% arrange(pct_socly), 10)[c("ONET18_Title_LY","ONET18_Title", "pct_socly")]
# Most stable jobs: ONET measure
head(distinct(subset(j1, ONET18_SOC == ONET18_SOC_LY) %>% arrange(pct_socly), 10))[c("ONET18_Title_LY","ONET18_Title", "pct_socly")]
# Most stable jobs: ONET measure
head(subset(j1, ONET18_SOC == ONET18_SOC_LY) %>% arrange(pct_socly), 10)[c("ONET18_Title_LY","ONET18_Title", "pct_socly")]
# Least stable jobs: OCC measure
head(subset(j1, same_cps == 1) %>% arrange(desc(pct_socly)), 10)[c("ONET18_Title_LY","ONET18_Title", "pct_socly")]
# Least stable jobs: ONET measure
head(subset(j1, ONET18_SOC == ONET18_SOC_LY) %>% arrange(desc(pct_socly)), 10)[c("ONET18_Title_LY","ONET18_Title", "pct_socly")]
# Most stable jobs: OCC measure
head(subset(j1, same_cps == 1) %>% arrange(pct_socly), 10)[c("ONET18_Title_LY","ONET18_Title", "pct_socly")]
# Most stable jobs: ONET measure
head(subset(j1, ONET18_SOC == ONET18_SOC_LY) %>% arrange(pct_socly), 10)[c("ONET18_Title_LY","ONET18_Title", "pct_socly")]
# ------------------------------------------------------------------------------------------------------#
# STEP 0. SET UP WORKSPACE AND PREPARE DATA FOR Analysis
# ------------------------------------------------------------------------------------------------------#
rm(list = ls())
# Set working directory
setwd('C:/Users/axell/OneDrive/Documents/MIT/J-WEL/Job Distance')
# Load packages
packages <- c("knitr",
"ggplot2",
"scales",
"plyr",
"dplyr",
"tidyr",
"gridExtra",
"grid",
"readxl",
"stringr",
"reshape2",
"kableExtra",
"stargazer",
"Hmisc",
"caret",
"ipumsr",
"R.utils",
"sandwich",
"lmtest",
"htmltab")
lapply(packages, require, character.only = TRUE)
options(scipen = 999)
knitr::opts_chunk$set(echo = TRUE, fig.pos= "H")
# Set the latex engine path
Sys.setenv(PATH = paste(Sys.getenv("PATH"), "C:\\Users\\axell\\AppData\\Local\\MiKTeX\\2.9\\miktex\\bin\\x64", sep=.Platform$path.sep))
knitr::opts_chunk$set(fig.pos = 'H')
### Read in CPS Data
ddi <- read_ipums_ddi("cps_00003.xml")
### Read in CPS Data
ddi <- read_ipums_ddi("cps_00003.xml")
cps <- read_ipums_micro(ddi, data_file = "cps_00003.dat.gz", verbose = FALSE)
cps$CPSID <- as.character(cps$CPSID)
cps$CPSIDP <- as.character(cps$CPSIDP)
# Keep only respondants from 2011-2019 who are part of the ASEC and in the Labor force in the current year
cps  <- subset(cps, ASECFLAG %in% c(1, 2) &  LABFORCE == 2) %>%
subset(., YEAR %in% c(2011:2019))
# Create an ID variable to account for ASEC oversample
cps <- cps %>% mutate(ID = ifelse(CPSIDP == "0", paste0(YEAR, "ASEC", 1:n()), CPSIDP))
# subset to people who had jobs both years
cps$OCC <- as.numeric(as.character(cps$OCC))
cps$OCCLY <- as.numeric(as.character(cps$OCCLY))
cps$OCC[cps$OCC == 0] <- NA
cps$OCCLY[cps$OCCLY == 0] <- NA
cps <- subset(cps, !is.na(OCC) & !is.na(OCCLY))
### Read in Occupational Information
occ <- read.csv("OCC Codes 2011-2019.csv")
occ$OccupationDescription_LY <- occ$OccupationDescription
cps <- merge(x = cps, y = occ[c("OCC", "OccupationDescription")], by = "OCC", all.x = T) %>%
merge(x = .,   y = occ[c("OCC", "OccupationDescription_LY")], by.x = "OCCLY", by.y = "OCC", all.x = T)
# Import the SOC/O*Net and CPS/SOC xwalks from https://www.bls.gov/emp/documentation/crosswalks.htm
xwalk = merge(x = read_excel("./nem-occcode-cps-crosswalk.xlsx", skip = 4)[c(2,4:5)],
y = read_excel("./nem-onet-to-soc-crosswalk.xlsx", skip = 4)[c(2,4)],
by.x = "Hybrid SOC Code",
by.y = "SOC Code",
all = T)
names(xwalk) <- c( "HSOC_OCC", "CPS_OCC", "CPS_Title", "ONET10_SOC_OCC")
# Import the SOC/O*Net and CPS/SOC xwalks from https://www.onetcenter.org/taxonomy/2010/soc2018.html
xwalk = merge(x = xwalk,
y = read_excel("./2010_to_2018_SOC_Crosswalk.xlsx", skip = 3)[c(1,3:4)],
by.x = "ONET10_SOC_OCC",
by.y = "O*NET-SOC 2010 Code",
all = T)
names(xwalk)[5:6] <- c("ONET18_SOC", "ONET18_Title")
xwalk <- distinct(xwalk, CPS_OCC, ONET18_SOC, .keep_all = T)
# Create SOC-Level flag
xwalk$SOCLvl <- ifelse(str_sub(as.character(xwalk$ONET10_SOC_OCC), -2, -1) == "00", 1, 0)
xwalk$ONET10_SOC <- substring(as.character(xwalk$ONET10_SOC_OCC), 1, 7)
xwalk_simp <- distinct(xwalk, CPS_OCC, ONET18_SOC, .keep_all = T) %>%
subset(., select = -c(HSOC_OCC, ONET10_SOC_OCC))
# ------------------------------------------------------------------------------------------------------#
# STEP 2. AGGREGATE ALL CURRENT YEAR AND LAST YEAR JOB COMBINATIONS
# ------------------------------------------------------------------------------------------------------#
# Aggregate all combinations using CPS OCC Codes
jc <- cps %>%
group_by(OCC, OCCLY) %>%
summarise(count = sum(ASECWT))
# Merge on ONET codes all
jc <- merge(x = jc,
y = subset(xwalk_simp, select =-c(SOCLvl)),
by.x = "OCC", by.y = "CPS_OCC",
all.x = T)
jc <- merge(x = jc,
y = subset(xwalk_simp, select =-c(SOCLvl)),
by.x = "OCCLY", by.y = "CPS_OCC",
suffixes = c("","_LY"),
all.x = T)
# Adjust weights to account for multiple matches in xwalks
jc <- merge(x = subset(jc, select = -c(ONET10_SOC, ONET10_SOC_LY, CPS_Title_LY, CPS_Title)),
y = jc %>% group_by(OCC, OCCLY) %>%
summarise(n = n()),
by = c('OCC', 'OCCLY'), all = T) %>%
mutate(., count = as.numeric(as.character(count))/n,
same_cps = ifelse(OCC == OCCLY, 1, 0)) %>%
subset(select = -c(OCC, OCCLY)) %>%
subset(., !is.na(ONET18_SOC) & !is.na(ONET18_SOC_LY)) # investigate the issue of 165 missing records at some point
# ------------------------------------------------------------------------------------------------------#
# STEP 3a. CALCULATE JOB COMBINATION FREQUENCY: Overall and by Title
# ------------------------------------------------------------------------------------------------------#
j1 <- jc
total = sum(j1$count)
j1 <- j1 %>% mutate(pct_tot = (count/total)*100)
j1 <- j1 %>%
group_by(ONET18_SOC_LY) %>%
mutate(count_socly = sum(count))
j1$pct_socly <- (j1$count/j1$count_socly)*100
# ------------------------------------------------------------------------------------------------------#
# STEP 3b. CATEGORIZE JOB CHANGE TYPES
# ------------------------------------------------------------------------------------------------------#
j1 <- j1 %>%
mutate(in_grp = ifelse(substring(ONET18_SOC, 1, 2) == substring(ONET18_SOC_LY, 1, 2), 1, 0),
in_minor_grp = ifelse(substring(ONET18_SOC, 1, 5) == substring(ONET18_SOC_LY, 1, 5), 1, 0),
in_broad_occ = ifelse(substring(ONET18_SOC, 1, 6) == substring(ONET18_SOC_LY, 1, 6), 1, 0))
j1 <- j1[c("count", "n","ONET18_SOC_LY","ONET18_SOC","ONET18_Title_LY","ONET18_Title", "pct_tot", "count_socly", "pct_socly", "same_cps", "in_grp",     "in_minor_grp", "in_broad_occ")]
# write.csv(x=j1, file="JobCY_LY_2011to19.csv",  row.names = FALSE)
# ------------------------------------------------------------------------------------------------------#
# STEP 4a. FOR CHANGES ONLY: CALCULATE JOB CHANGE FREQUENCY: Overall and by Title
# ------------------------------------------------------------------------------------------------------#
#j2 <- subset(jc, ONET18_SOC != ONET18_SOC_LY)
j2 <- subset(jc, same_cps != 1)
total = sum(j2$count)
j2 <- j2 %>% mutate(pct_tot = (count/total)*100)
j2 <- j2 %>%
group_by(ONET18_SOC_LY) %>%
mutate(count_socly = sum(count)) %>%
subset(., select =-c(n))
j2$pct_socly <- (j2$count/j2$count_socly)*100
# ------------------------------------------------------------------------------------------------------#
# STEP 4b.  FOR CHANGES ONLY: CATEGORIZE JOB CHANGE TYPES
# ------------------------------------------------------------------------------------------------------#
j2 <- j2 %>%
mutate(in_grp = ifelse(substring(ONET18_SOC, 1, 2) == substring(ONET18_SOC_LY, 1, 2), 1, 0),
in_minor_grp = ifelse(substring(ONET18_SOC, 1, 5) == substring(ONET18_SOC_LY, 1, 5), 1, 0),
in_broad_occ = ifelse(substring(ONET18_SOC, 1, 6) == substring(ONET18_SOC_LY, 1, 6), 1, 0))
j2 <- j2[c("ONET18_SOC", "ONET18_SOC_LY", "ONET18_Title", "ONET18_Title_LY", "count", "pct_tot", "count_socly", "pct_socly", "in_grp", "in_minor_grp", "in_broad_occ")]
# write.csv(x=j2, file="JobChanges_2011to19.csv",  row.names = FALSE)
# ------------------------------------------------------------------------------------------------------#
# STEP 0. SET UP WORKSPACE AND PREPARE DATA FOR Analysis
# ------------------------------------------------------------------------------------------------------#
rm(list = ls())
# Set working directory
setwd('C:/Users/axell/OneDrive/Documents/MIT/J-WEL/Job Distance')
# Load packages
packages <- c("knitr",
"ggplot2",
"scales",
"plyr",
"dplyr",
"tidyr",
"gridExtra",
"grid",
"readxl",
"stringr",
"reshape2",
"kableExtra",
"stargazer",
"Hmisc",
"caret",
"ipumsr",
"R.utils",
"sandwich",
"lmtest",
"htmltab")
lapply(packages, require, character.only = TRUE)
options(scipen = 999)
knitr::opts_chunk$set(echo = TRUE, fig.pos= "H")
# Set the latex engine path
Sys.setenv(PATH = paste(Sys.getenv("PATH"), "C:\\Users\\axell\\AppData\\Local\\MiKTeX\\2.9\\miktex\\bin\\x64", sep=.Platform$path.sep))
knitr::opts_chunk$set(fig.pos = 'H')
# ------------------------------------------------------------------------------------------------------#
# STEP 1. IMPORT DATA
# ------------------------------------------------------------------------------------------------------#
### Read in CPS Data
ddi <- read_ipums_ddi("cps_00003.xml")
cps <- read_ipums_micro(ddi, data_file = "cps_00003.dat.gz", verbose = FALSE)
cps$CPSID <- as.character(cps$CPSID)
cps$CPSIDP <- as.character(cps$CPSIDP)
# Keep only respondants from 2011-2019 who are part of the ASEC and in the Labor force in the current year
cps  <- subset(cps, ASECFLAG %in% c(1, 2) &  LABFORCE == 2) %>%
subset(., YEAR %in% c(2011:2019))
# Create an ID variable to account for ASEC oversample
cps <- cps %>% mutate(ID = ifelse(CPSIDP == "0", paste0(YEAR, "ASEC", 1:n()), CPSIDP))
# subset to people who had jobs both years
cps$OCC <- as.numeric(as.character(cps$OCC))
cps$OCCLY <- as.numeric(as.character(cps$OCCLY))
cps$OCC[cps$OCC == 0] <- NA
cps$OCCLY[cps$OCCLY == 0] <- NA
cps <- subset(cps, !is.na(OCC) & !is.na(OCCLY))
### Read in Occupational Information
occ <- read.csv("OCC Codes 2011-2019.csv")
occ$OccupationDescription_LY <- occ$OccupationDescription
cps <- merge(x = cps, y = occ[c("OCC", "OccupationDescription")], by = "OCC", all.x = T) %>%
merge(x = .,   y = occ[c("OCC", "OccupationDescription_LY")], by.x = "OCCLY", by.y = "OCC", all.x = T)
# Import the SOC/O*Net and CPS/SOC xwalks from https://www.bls.gov/emp/documentation/crosswalks.htm
xwalk = merge(x = read_excel("./nem-occcode-cps-crosswalk.xlsx", skip = 4)[c(2,4:5)],
y = read_excel("./nem-onet-to-soc-crosswalk.xlsx", skip = 4)[c(2,4)],
by.x = "Hybrid SOC Code",
by.y = "SOC Code",
all = T)
names(xwalk) <- c( "HSOC_OCC", "CPS_OCC", "CPS_Title", "ONET10_SOC_OCC")
# Import the SOC/O*Net and CPS/SOC xwalks from https://www.onetcenter.org/taxonomy/2010/soc2018.html
xwalk = merge(x = xwalk,
y = read_excel("./2010_to_2018_SOC_Crosswalk.xlsx", skip = 3)[c(1,3:4)],
by.x = "ONET10_SOC_OCC",
by.y = "O*NET-SOC 2010 Code",
all = T)
names(xwalk)[5:6] <- c("ONET18_SOC", "ONET18_Title")
xwalk <- distinct(xwalk, CPS_OCC, ONET18_SOC, .keep_all = T)
# Create SOC-Level flag
xwalk$SOCLvl <- ifelse(str_sub(as.character(xwalk$ONET10_SOC_OCC), -2, -1) == "00", 1, 0)
xwalk$ONET10_SOC <- substring(as.character(xwalk$ONET10_SOC_OCC), 1, 7)
xwalk_simp <- distinct(xwalk, CPS_OCC, ONET18_SOC, .keep_all = T) %>%
subset(., select = -c(HSOC_OCC, ONET10_SOC_OCC))
# ------------------------------------------------------------------------------------------------------#
# STEP 2. AGGREGATE ALL CURRENT YEAR AND LAST YEAR JOB COMBINATIONS
# ------------------------------------------------------------------------------------------------------#
# Aggregate all combinations using CPS OCC Codes
jc <- cps %>%
group_by(OCC, OCCLY) %>%
summarise(count = sum(ASECWT))
# Merge on ONET codes all
jc <- merge(x = jc,
y = subset(xwalk_simp, select =-c(SOCLvl)),
by.x = "OCC", by.y = "CPS_OCC",
all.x = T)
jc <- merge(x = jc,
y = subset(xwalk_simp, select =-c(SOCLvl)),
by.x = "OCCLY", by.y = "CPS_OCC",
suffixes = c("","_LY"),
all.x = T)
# Adjust weights to account for multiple matches in xwalks
jc <- merge(x = subset(jc, select = -c(ONET10_SOC, ONET10_SOC_LY, CPS_Title_LY, CPS_Title)),
y = jc %>% group_by(OCC, OCCLY) %>%
summarise(n = n()),
by = c('OCC', 'OCCLY'), all = T) %>%
mutate(., count = as.numeric(as.character(count))/n,
same_cps = ifelse(OCC == OCCLY, 1, 0)) %>%
subset(select = -c(OCC, OCCLY)) %>%
subset(., !is.na(ONET18_SOC) & !is.na(ONET18_SOC_LY)) # investigate the issue of 165 missing records at some point
# ------------------------------------------------------------------------------------------------------#
# STEP 3a. CALCULATE JOB COMBINATION FREQUENCY: Overall and by Title
# ------------------------------------------------------------------------------------------------------#
j1 <- jc
total = sum(j1$count)
j1 <- j1 %>% mutate(pct_tot = (count/total)*100)
j1 <- j1 %>%
group_by(ONET18_SOC_LY) %>%
mutate(count_socly = sum(count))
j1$pct_socly <- (j1$count/j1$count_socly)*100
# ------------------------------------------------------------------------------------------------------#
# STEP 3b. CATEGORIZE JOB CHANGE TYPES
# ------------------------------------------------------------------------------------------------------#
j1 <- j1 %>%
mutate(in_grp = ifelse(substring(ONET18_SOC, 1, 2) == substring(ONET18_SOC_LY, 1, 2), 1, 0),
in_minor_grp = ifelse(substring(ONET18_SOC, 1, 5) == substring(ONET18_SOC_LY, 1, 5), 1, 0),
in_broad_occ = ifelse(substring(ONET18_SOC, 1, 6) == substring(ONET18_SOC_LY, 1, 6), 1, 0))
j1 <- j1[c("count", "n","ONET18_SOC_LY","ONET18_SOC","ONET18_Title_LY","ONET18_Title", "pct_tot", "count_socly", "pct_socly", "same_cps", "in_grp",     "in_minor_grp", "in_broad_occ")]
write.csv(x=j1, file="JobCY_LY_2011to19.csv",  row.names = FALSE)
# ------------------------------------------------------------------------------------------------------#
# STEP 4a. FOR CHANGES ONLY: CALCULATE JOB CHANGE FREQUENCY: Overall and by Title
# ------------------------------------------------------------------------------------------------------#
#j2 <- subset(jc, ONET18_SOC != ONET18_SOC_LY)
j2 <- subset(jc, same_cps != 1)
total = sum(j2$count)
j2 <- j2 %>% mutate(pct_tot = (count/total)*100)
j2 <- j2 %>%
group_by(ONET18_SOC_LY) %>%
mutate(count_socly = sum(count)) %>%
subset(., select =-c(n))
j2$pct_socly <- (j2$count/j2$count_socly)*100
# ------------------------------------------------------------------------------------------------------#
# STEP 4b.  FOR CHANGES ONLY: CATEGORIZE JOB CHANGE TYPES
# ------------------------------------------------------------------------------------------------------#
j2 <- j2 %>%
mutate(in_grp = ifelse(substring(ONET18_SOC, 1, 2) == substring(ONET18_SOC_LY, 1, 2), 1, 0),
in_minor_grp = ifelse(substring(ONET18_SOC, 1, 5) == substring(ONET18_SOC_LY, 1, 5), 1, 0),
in_broad_occ = ifelse(substring(ONET18_SOC, 1, 6) == substring(ONET18_SOC_LY, 1, 6), 1, 0))
j2 <- j2[c("ONET18_SOC", "ONET18_SOC_LY", "ONET18_Title", "ONET18_Title_LY", "count", "pct_tot", "count_socly", "pct_socly", "in_grp", "in_minor_grp", "in_broad_occ")]
write.csv(x=j2, file="JobChanges_2011to19.csv",  row.names = FALSE)
# ------------------------------------------------------------------------------------------------------#
# STEP 0. SET UP WORKSPACE AND PREPARE DATA FOR Analysis
# ------------------------------------------------------------------------------------------------------#
rm(list = ls())
# Set working directory
setwd('C:/Users/axell/OneDrive/Documents/MIT/J-WEL/Job Distance')
# Load packages
packages <- c("knitr",
"ggplot2",
"scales",
"plyr",
"dplyr",
"tidyr",
"gridExtra",
"grid",
"readxl",
"stringr",
"reshape2",
"kableExtra",
"stargazer",
"Hmisc",
"caret",
"ipumsr",
"R.utils",
"sandwich",
"lmtest",
"htmltab")
lapply(packages, require, character.only = TRUE)
options(scipen = 999)
knitr::opts_chunk$set(echo = TRUE, fig.pos= "H")
# Set the latex engine path
Sys.setenv(PATH = paste(Sys.getenv("PATH"), "C:\\Users\\axell\\AppData\\Local\\MiKTeX\\2.9\\miktex\\bin\\x64", sep=.Platform$path.sep))
knitr::opts_chunk$set(fig.pos = 'H')
# ------------------------------------------------------------------------------------------------------#
# STEP 1. IMPORT DATA
# ------------------------------------------------------------------------------------------------------#
### Read in CPS Data
ddi <- read_ipums_ddi("cps_00003.xml")
cps <- read_ipums_micro(ddi, data_file = "cps_00003.dat.gz", verbose = FALSE)
cps$CPSID <- as.character(cps$CPSID)
cps$CPSIDP <- as.character(cps$CPSIDP)
# Keep only respondants from 2011-2019 who are part of the ASEC and in the Labor force in the current year
cps  <- subset(cps, ASECFLAG %in% c(1, 2) &  LABFORCE == 2) %>%
subset(., YEAR %in% c(2011:2019))
# Create an ID variable to account for ASEC oversample
cps <- cps %>% mutate(ID = ifelse(CPSIDP == "0", paste0(YEAR, "ASEC", 1:n()), CPSIDP))
# subset to people who had jobs both years
cps$OCC <- as.numeric(as.character(cps$OCC))
cps$OCCLY <- as.numeric(as.character(cps$OCCLY))
cps$OCC[cps$OCC == 0] <- NA
cps$OCCLY[cps$OCCLY == 0] <- NA
cps <- subset(cps, !is.na(OCC) & !is.na(OCCLY))
### Read in Occupational Information
occ <- read.csv("OCC Codes 2011-2019.csv")
occ$OccupationDescription_LY <- occ$OccupationDescription
cps <- merge(x = cps, y = occ[c("OCC", "OccupationDescription")], by = "OCC", all.x = T) %>%
merge(x = .,   y = occ[c("OCC", "OccupationDescription_LY")], by.x = "OCCLY", by.y = "OCC", all.x = T)
# Import the SOC/O*Net and CPS/SOC xwalks from https://www.bls.gov/emp/documentation/crosswalks.htm
xwalk = merge(x = read_excel("./nem-occcode-cps-crosswalk.xlsx", skip = 4)[c(2,4:5)],
y = read_excel("./nem-onet-to-soc-crosswalk.xlsx", skip = 4)[c(2,4)],
by.x = "Hybrid SOC Code",
by.y = "SOC Code",
all = T)
names(xwalk) <- c( "HSOC_OCC", "CPS_OCC", "CPS_Title", "ONET10_SOC_OCC")
# Import the SOC/O*Net and CPS/SOC xwalks from https://www.onetcenter.org/taxonomy/2010/soc2018.html
xwalk = merge(x = xwalk,
y = read_excel("./2010_to_2018_SOC_Crosswalk.xlsx", skip = 3)[c(1,3:4)],
by.x = "ONET10_SOC_OCC",
by.y = "O*NET-SOC 2010 Code",
all = T)
names(xwalk)[5:6] <- c("ONET18_SOC", "ONET18_Title")
xwalk <- distinct(xwalk, CPS_OCC, ONET18_SOC, .keep_all = T)
# Create SOC-Level flag
xwalk$SOCLvl <- ifelse(str_sub(as.character(xwalk$ONET10_SOC_OCC), -2, -1) == "00", 1, 0)
xwalk$ONET10_SOC <- substring(as.character(xwalk$ONET10_SOC_OCC), 1, 7)
xwalk_simp <- distinct(xwalk, CPS_OCC, ONET18_SOC, .keep_all = T) %>%
subset(., select = -c(HSOC_OCC, ONET10_SOC_OCC))
# ------------------------------------------------------------------------------------------------------#
# STEP 2. AGGREGATE ALL CURRENT YEAR AND LAST YEAR JOB COMBINATIONS
# ------------------------------------------------------------------------------------------------------#
# Aggregate all combinations using CPS OCC Codes
jc <- cps %>%
group_by(OCC, OCCLY) %>%
summarise(count = sum(ASECWT))
# Merge on ONET codes all
jc <- merge(x = jc,
y = subset(xwalk_simp, select =-c(SOCLvl)),
by.x = "OCC", by.y = "CPS_OCC",
all.x = T)
jc <- merge(x = jc,
y = subset(xwalk_simp, select =-c(SOCLvl)),
by.x = "OCCLY", by.y = "CPS_OCC",
suffixes = c("","_LY"),
all.x = T)
# Adjust weights to account for multiple matches in xwalks
jc <- merge(x = subset(jc, select = -c(ONET10_SOC, ONET10_SOC_LY, CPS_Title_LY, CPS_Title)),
y = jc %>% group_by(OCC, OCCLY) %>%
summarise(n = n()),
by = c('OCC', 'OCCLY'), all = T) %>%
mutate(., count = as.numeric(as.character(count))/n,
same_cps = ifelse(OCC == OCCLY, 1, 0)) %>%
subset(select = -c(OCC, OCCLY)) %>%
subset(., !is.na(ONET18_SOC) & !is.na(ONET18_SOC_LY)) # investigate the issue of 165 missing records at some point
# ------------------------------------------------------------------------------------------------------#
# STEP 3a. CALCULATE JOB COMBINATION FREQUENCY: Overall and by Title
# ------------------------------------------------------------------------------------------------------#
j1 <- jc
total = sum(j1$count)
j1 <- j1 %>% mutate(pct_tot = (count/total)*100)
j1 <- j1 %>%
group_by(ONET18_SOC_LY) %>%
mutate(count_socly = sum(count))
j1$pct_socly <- (j1$count/j1$count_socly)*100
# ------------------------------------------------------------------------------------------------------#
# STEP 3b. CATEGORIZE JOB CHANGE TYPES
# ------------------------------------------------------------------------------------------------------#
j1 <- j1 %>%
mutate(in_grp = ifelse(substring(ONET18_SOC, 1, 2) == substring(ONET18_SOC_LY, 1, 2), 1, 0),
in_minor_grp = ifelse(substring(ONET18_SOC, 1, 5) == substring(ONET18_SOC_LY, 1, 5), 1, 0),
in_broad_occ = ifelse(substring(ONET18_SOC, 1, 6) == substring(ONET18_SOC_LY, 1, 6), 1, 0))
j1 <- j1[c("count", "n","ONET18_SOC_LY","ONET18_SOC","ONET18_Title_LY","ONET18_Title", "pct_tot", "count_socly", "pct_socly", "same_cps", "in_grp",     "in_minor_grp", "in_broad_occ")]
write.csv(x=j1, file="JobCY_LY_2011to19.csv",  row.names = FALSE)
# ------------------------------------------------------------------------------------------------------#
# STEP 4a. FOR CHANGES ONLY: CALCULATE JOB CHANGE FREQUENCY: Overall and by Title
# ------------------------------------------------------------------------------------------------------#
#j2 <- subset(jc, ONET18_SOC != ONET18_SOC_LY)
j2 <- subset(jc, same_cps != 1)
total = sum(j2$count)
j2 <- j2 %>% mutate(pct_tot = (count/total)*100)
j2 <- j2 %>%
group_by(ONET18_SOC_LY) %>%
mutate(count_socly = sum(count)) %>%
subset(., select =-c(n))
j2$pct_socly <- (j2$count/j2$count_socly)*100
# ------------------------------------------------------------------------------------------------------#
# STEP 4b.  FOR CHANGES ONLY: CATEGORIZE JOB CHANGE TYPES
# ------------------------------------------------------------------------------------------------------#
j2 <- j2 %>%
mutate(in_grp = ifelse(substring(ONET18_SOC, 1, 2) == substring(ONET18_SOC_LY, 1, 2), 1, 0),
in_minor_grp = ifelse(substring(ONET18_SOC, 1, 5) == substring(ONET18_SOC_LY, 1, 5), 1, 0),
in_broad_occ = ifelse(substring(ONET18_SOC, 1, 6) == substring(ONET18_SOC_LY, 1, 6), 1, 0))
j2 <- j2[c("ONET18_SOC", "ONET18_SOC_LY", "ONET18_Title", "ONET18_Title_LY", "count", "pct_tot", "count_socly", "pct_socly", "in_grp", "in_minor_grp", "in_broad_occ")]
write.csv(x=j2, file="JobChanges_2011to19.csv",  row.names = FALSE)
# Load packages and set options
rm(list = ls())
setwd('C:/Users/axell/OneDrive/Documents/MIT/6.431')
packages <- c("knitr",
"ggplot2",
"scales",
"plyr",
"dplyr",
"tidyr",
"stats")
lapply(packages, require, character.only = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.pos= "H")
# Set the latex engine path
Sys.setenv(PATH = paste(Sys.getenv("PATH"), "C:\\Users\\axell\\AppData\\Local\\MiKTeX\\2.9\\miktex\\bin\\x64", sep=.Platform$path.sep))
knitr::opts_chunk$set(fig.pos = 'H')
# PROGRAM NAME: Goodness Indicator
# DESCRIPTION: Creating a GI from the  wage and growth changes associated with a job change
# PROGRAMMER(S): Axelle Clochard
# DATE WRITTEN: 09/22/2020
# LAST UPDATED: 09/22/2020
# STEP 0. SET UP WORKSPACE AND LOAD DATA
# ---------------------------------------------------------------------------------------------------#
# ---------------------------------------------------------------------------------------------------#
# A. SET WORKSPACE PARAMS
# ------------------------#
rm(list = ls())
# Set working directory to where file is
# script.dir <- dirname(rstudioapi::getActiveDocumentContext()$path)
# setwd(script.dir)
setwd('C:/Users/axell/OneDrive/Documents/MIT/J-WEL/employment/CPS Job Changes')
# install packages if necessary
packages <- c("ggplot2",
"haven",
"scales",
"dplyr",
"gridExtra",
"grid",
"xlsx",
"reshape2",
"stargazer",
"Hmisc",
"readxl",
"httr",
"Hmisc")
install_list <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(install_list)) install.packages(install_list)
lapply(packages, require, character.only = TRUE)
# B. O*NET DATA
# ---------------#
#ONET 2010 to SOC 2018 (BLS) xwalk from https://www.onetcenter.org/taxonomy/2010/soc2018.html
onet = read_excel("./2010_to_2018_SOC_Crosswalk.xlsx", skip = 3)
View(onet)
names(onet)
names(onet) = c("onet_2010_soc", "onet_2010_title", "SOC_2018", "SOC_title_2018" )
# C. BLS WAGE DATA (https://www.bls.gov/oes/current/oes_nat.htm)
# ---------------------------------------------------------------------#
blsw = read_excel("./national_M2019_dl.xlsx", skip = 0)
hb_w = read_excel("./national_M2019_dl.xlsx", skip = 0, sheet = 2)
# C. BLS GROWTH DATA (https://www.bls.gov/emp/tables/emp-by-detailed-occupation.htm)
# ------------------------------------------------------------------------------------#
blsg = read_excel("./occupation.xlsx", sheet = 3)
old_names = blsg[1:4,]
View(blsw)
View(onet)
